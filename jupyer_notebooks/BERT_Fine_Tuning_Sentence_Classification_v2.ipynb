{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning Tutorial with PyTorch\n",
        "\n",
        "By Chris McCormick and Nick Ryan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPgpITmdwvX0"
      },
      "source": [
        "*Revised on 12/13/19 to use the new [transformers](https://github.com/huggingface/transformers) interface.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## 1.1. Using Colab GPU for Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "\n",
        "Google Colab offers free GPUs and TPUs! Since we'll be training a large neural network it's best to take advantage of this (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
        "\n",
        "A GPU can be added by going to the menu and selecting:\n",
        "\n",
        "`Edit ðŸ¡’ Notebook Settings ðŸ¡’ Hardware accelerator ðŸ¡’ (GPU)`\n",
        "\n",
        "Then run the following cell to confirm that the GPU is detected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "bac79307-973d-449b-c229-80a22ee613c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/new-stg/home/banghua/anaconda3/envs/LLM/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA RTX A6000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "## 1.2. Installing the Hugging Face Library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N2UDLevYWn"
      },
      "source": [
        "\n",
        "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
        "\n",
        "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
        "\n",
        "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxddqmruamSj"
      },
      "source": [
        "The code in this notebook is actually a simplified version of the [run_glue.py](https://github.com/huggingface/transformers/blob/master/examples/run_glue.py) example script from huggingface.\n",
        "\n",
        "`run_glue.py` is a helpful utility which allows you to pick which GLUE benchmark task you want to run on, and which pre-trained model you want to use (you can see the list of possible models [here](https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69)). It also supports using either the CPU, a single GPU, or multiple GPUs. It even supports using 16-bit precision if you want further speed up.\n",
        "\n",
        "Unfortunately, all of this configurability comes at the cost of *readability*. In this Notebook, we've simplified the code greatly and added plenty of comments to make it clear what's going on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# 2. Loading CoLA Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## 2.2. Parse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeyVCXT31EZQ"
      },
      "source": [
        "We can see from the file names that both `tokenized` and `raw` versions of the data are available.\n",
        "\n",
        "We can't use the pre-tokenized version because, in order to apply the pre-trained BERT, we *must* use the tokenizer provided by the model. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "_UkeC7SG2krJ",
        "outputId": "83fcecd4-b718-4bc8-9026-e6d1151d83a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training sentences: 118,094\n",
            "\n",
            "Number of validation sentences: 14,601\n",
            "\n",
            "Number of testing sentences: 14,935\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df_train = pd.read_csv(\"~/med264/Dataset1/day1_30mortality_train.csv\", index_col=0)\n",
        "df_val = pd.read_csv(\"~/med264/Dataset1/day1_30mortality_val.csv\", index_col=0)\n",
        "df_test = pd.read_csv(\"~/med264/Dataset1/day1_30mortality_test.csv\", index_col=0)\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df_train.shape[0]))\n",
        "print('Number of validation sentences: {:,}\\n'.format(df_val.shape[0]))\n",
        "print('Number of testing sentences: {:,}\\n'.format(df_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "outputs": [],
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences_train = df_train.TEXT.values\n",
        "labels_train = df_train.Label.values\n",
        "sentences_val = df_val.TEXT.values\n",
        "labels_val = df_val.Label.values\n",
        "sentences_test = df_test.TEXT.values\n",
        "labels_test = df_test.Label.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "3259bbb9cfbf4652944d6a63779c8536",
            "03eb5cad0dd745feb519ae16bc13afd5",
            "ab7f43db105a4c059816b83b8e3050ec",
            "02c860af048a48039571df1ac10703a0",
            "3276e0075f924285aaa17252d34217ba",
            "82b16898863445b485e301b75b1c918c",
            "7fada7d50b514b38ad70fa3baf613c6f",
            "b4e9766eb48c4db09d5e9ec558802d25",
            "3496eb8998e64a38bf2ea922eec5f093",
            "e1f85d855dc54d93b07370119c3fb96b",
            "6ce09be5acce441494710b3c0cbc6169",
            "9b263a3168674657b14223e58611f294",
            "e02c53a9b05047b0a3bfc9e47735ee43",
            "b15d78f0355e4c55b9ce4480d42bd67c",
            "4bb4b4d8abb34ffbafa2194402d755f8",
            "eb60945d776d4b5a92870fa3371471f6",
            "ff7286cb5f4e4afdb9b8403265e51f0c",
            "fefd62e5e0064bb6a8ed1f750309b8a1",
            "4171dca739984eb68291b7e8f337f372",
            "9ed6e953f4d74267a34be03f6b19283a",
            "94d9470c01bd419dbf9f55fa69487ac9",
            "4ae1954f09a04e0cb50a01a0154f64ec",
            "261c73d7337e4fd89c5512fd7cc801b9",
            "99320230aa154969ac7efcb4bd08e93a",
            "1b80d80718874a95b805bca384538f9f",
            "f1fb5bd99db34449aaa0775649c33ade",
            "faa00d6df14a4229b40388dbf79b911f",
            "52b73c5ed8354070bbc22b6b74bde680",
            "a747919a41ac43ae9baaf22c5654ca02",
            "318e7d7d83c447a793316c7dda14a06d",
            "cf4b37cd06c34b6c995b02e30003ff38",
            "942cfc1c25e54f088288dd44c9c708e9",
            "900a26c928b74d668a77dc97cc22995e",
            "338a08d6c85e48e0b8ef1c0a083043fb",
            "55d9d13ce82b4950a54b33bb6733ea58",
            "8ae18003614946a4b0cb39b81f5a6063",
            "427bed3eb7e743f387a0dd6c23f031e9",
            "632c81708e674a61b848d1fccab30084",
            "ec7c4858c9be4d359b77d390c432dbbb",
            "599f7a8f19874431bd445deda4c7b273",
            "571e6cb89b8d40cbaa812a53f895acdc",
            "6a2a3be6805048539e68be9c9db64cc5",
            "9348b3637d2a4d2088281c8e34d98f3e",
            "41ba494ceeba44de99f69891d4fcfed7"
          ]
        },
        "id": "Z474sSC6oe7A",
        "outputId": "98043c48-fe54-4d6f-ff35-ac3d33ee28d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('medicalai/ClinicalBERT', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLIbudgfh6F0",
        "outputId": "a07b82c7-99cc-41db-e017-1ba73c3537c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Original:  11:12 am chest (pa & lat) clip # reason: eval for infiltrate medical condition: 35 year old woman with vomiting reason for this examination: eval for infiltrate final report chest radiograph indication: vomiting, evaluation for infiltrates. comparison: . findings: as compared to the previous radiograph, there is no relevant change. no evidence of pneumonia or other pathological abnormalities. no pleural effusions. no pulmonary edema. normal size of the cardiac silhouette.\n",
            "Tokenized:  ['11', ':', '12', 'am', 'chest', '(', 'pa', '&', 'lat', ')', 'clip', '#', 'reason', ':', 'eva', '##l', 'for', 'in', '##fil', '##trat', '##e', 'medical', 'condition', ':', '35', 'year', 'old', 'woman', 'with', 'vom', '##iting', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', 'for', 'in', '##fil', '##trat', '##e', 'final', 'report', 'chest', 'radio', '##graph', 'indication', ':', 'vom', '##iting', ',', 'evaluation', 'for', 'in', '##fil', '##trat', '##es', '.', 'comparison', ':', '.', 'findings', ':', 'as', 'compared', 'to', 'the', 'previous', 'radio', '##graph', ',', 'there', 'is', 'no', 'relevant', 'change', '.', 'no', 'evidence', 'of', 'pne', '##umon', '##ia', 'or', 'other', 'path', '##ological', 'ab', '##normal', '##ities', '.', 'no', 'pl', '##eur', '##al', 'ef', '##fus', '##ions', '.', 'no', 'pu', '##lm', '##onar', '##y', 'ede', '##ma', '.', 'normal', 'size', 'of', 'the', 'card', '##iac', 'sil', '##hou', '##ette', '.']\n",
            "Token IDs:  [10193, 131, 10186, 10392, 94230, 113, 10931, 111, 12764, 114, 48545, 108, 27949, 131, 103730, 10161, 10142, 10106, 41784, 61908, 10112, 19436, 24713, 131, 10803, 10924, 12898, 18299, 10169, 11036, 48802, 27949, 10142, 10531, 65548, 131, 103730, 10161, 10142, 10106, 41784, 61908, 10112, 11070, 17553, 94230, 12429, 28176, 102383, 131, 11036, 48802, 117, 70204, 10142, 10106, 41784, 61908, 10171, 119, 56542, 131, 119, 79441, 131, 10146, 25626, 10114, 10105, 16741, 12429, 28176, 117, 11155, 10124, 10192, 44622, 15453, 119, 10192, 18713, 10108, 63821, 108689, 10280, 10345, 10684, 37013, 30975, 11357, 89304, 17285, 119, 10192, 20648, 12986, 10415, 56331, 55729, 15880, 119, 10192, 34597, 55183, 44320, 10157, 63679, 10369, 119, 16626, 15851, 10108, 10105, 23050, 46917, 33694, 25611, 14842, 119]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences_train[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeNIc4auFUdF"
      },
      "source": [
        "When we actually convert all of our sentences, we'll use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately.\n",
        "\n",
        "Before we can do that, though, we need to talk about some of BERT's formatting requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ"
      },
      "source": [
        "## 3.2. Sentences to IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M296yz577fV"
      },
      "source": [
        "The `tokenizer.encode` function combines multiple steps for us:\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "\n",
        "Oddly, this function can perform truncating for us, but doesn't handle padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bBdb3pt8LuQ",
        "outputId": "11ab1ae6-cc86-489b-b697-1606b4d990f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded input_ids_train.\n",
            "Loaded input_ids_valid.\n",
            "Loaded input_ids_test.\n",
            "Original:  11:12 am chest (pa & lat) clip # reason: eval for infiltrate medical condition: 35 year old woman with vomiting reason for this examination: eval for infiltrate final report chest radiograph indication: vomiting, evaluation for infiltrates. comparison: . findings: as compared to the previous radiograph, there is no relevant change. no evidence of pneumonia or other pathological abnormalities. no pleural effusions. no pulmonary edema. normal size of the cardiac silhouette.\n",
            "Token IDs: [101, 10193, 131, 10186, 10392, 94230, 113, 10931, 111, 12764, 114, 48545, 108, 27949, 131, 103730, 10161, 10142, 10106, 41784, 61908, 10112, 19436, 24713, 131, 10803, 10924, 12898, 18299, 10169, 11036, 48802, 27949, 10142, 10531, 65548, 131, 103730, 10161, 10142, 10106, 41784, 61908, 10112, 11070, 17553, 94230, 12429, 28176, 102383, 131, 11036, 48802, 117, 70204, 10142, 10106, 41784, 61908, 10171, 119, 56542, 131, 119, 79441, 131, 10146, 25626, 10114, 10105, 16741, 12429, 28176, 117, 11155, 10124, 10192, 44622, 15453, 119, 10192, 18713, 10108, 63821, 108689, 10280, 10345, 10684, 37013, 30975, 11357, 89304, 17285, 119, 10192, 20648, 12986, 10415, 56331, 55729, 15880, 119, 10192, 34597, 55183, 44320, 10157, 63679, 10369, 119, 16626, 15851, 10108, 10105, 23050, 46917, 33694, 25611, 14842, 119, 102]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Correct the path by expanding the tilde to the user's home directory\n",
        "file_path_train = os.path.expanduser('~/med264/Dataset1/input_ids_train.pickle')\n",
        "file_path_valid = os.path.expanduser('~/med264/Dataset1/input_ids_valid.pickle')\n",
        "file_path_test = os.path.expanduser('~/med264/Dataset1/input_ids_test.pickle')\n",
        "\n",
        "\n",
        "input_ids_train, input_ids_valid, input_ids_test = [], [], []\n",
        "\n",
        "if os.path.exists(file_path_train):\n",
        "    with open(file_path_train, 'rb') as f:\n",
        "        input_ids_train = pickle.load(f)\n",
        "    print('Loaded input_ids_train.')\n",
        "else:\n",
        "    for sent in tqdm(sentences_train):\n",
        "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
        "        input_ids_train.append(encoded_sent)\n",
        "    with open(file_path_train, 'wb') as f:\n",
        "        pickle.dump(input_ids_train, f)\n",
        "    print('Saved input_ids_train.')\n",
        "\n",
        "\n",
        "if os.path.exists(file_path_valid):\n",
        "    with open(file_path_valid, 'rb') as f:\n",
        "        input_ids_valid = pickle.load(f)\n",
        "    print('Loaded input_ids_valid.')\n",
        "else:\n",
        "    for sent in tqdm(sentences_val):\n",
        "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
        "        input_ids_valid.append(encoded_sent)\n",
        "    with open(file_path_valid, 'wb') as f:\n",
        "        pickle.dump(input_ids_valid, f)\n",
        "    print('Saved input_ids_valid.')\n",
        "\n",
        "if os.path.exists(file_path_test):\n",
        "    with open(file_path_test, 'rb') as f:\n",
        "        input_ids_test = pickle.load(f)\n",
        "    print('Loaded input_ids_test.')\n",
        "else:\n",
        "    for sent in tqdm(sentences_test):\n",
        "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
        "        input_ids_test.append(encoded_sent)\n",
        "    with open(file_path_test, 'wb') as f:\n",
        "            pickle.dump(input_ids_test, f)\n",
        "    print('Saved input_ids_test.')\n",
        "    \n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences_train[0])\n",
        "print('Token IDs:', input_ids_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhwCKszh6ych"
      },
      "source": [
        "## 3.3. Padding & Truncating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytsw1oIfnX0"
      },
      "source": [
        "Pad and truncate our sequences so that they all have the same length, `MAX_LEN`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqiWTDrn_nGB"
      },
      "source": [
        "First, what's the maximum sentence length in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhUZO9vc_l6T",
        "outputId": "3962e62a-f572-43ff-ac22-6ae8fa01ad0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max train sentence length:  1200\n",
            "Max valid sentence length:  1123\n",
            "Max test sentence length:  890\n"
          ]
        }
      ],
      "source": [
        "print('Max train sentence length: ', max([len(sen) for sen in input_ids_train]))\n",
        "print('Max valid sentence length: ', max([len(sen) for sen in input_ids_valid]))\n",
        "print('Max test sentence length: ', max([len(sen) for sen in input_ids_test]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp-54FcQ_p3h"
      },
      "source": [
        "Given that, let's choose MAX_LEN = 64 and apply the padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp9BPRd1tMIo",
        "outputId": "7530cd63-5916-4bee-dad5-f5533faf5aa5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-26 16:04:07.509407: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-26 16:04:10.391648: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-26 16:04:10.391696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-26 16:04:11.191724: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-26 16:04:12.346631: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-26 16:04:18.631167: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 512 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 512\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "input_ids_valid = pad_sequences(input_ids_valid, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDs-MYtYH8sL"
      },
      "source": [
        "## 3.4. Attention Masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhGulL1pExCT"
      },
      "source": [
        "The attention mask simply makes it explicit which tokens are actual words versus which are padding.\n",
        "\n",
        "The BERT vocabulary does not use the ID 0, so if a token ID is 0, then it's padding, and otherwise it's a real token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cDoC24LeEv3N"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks_train, attention_masks_valid, attention_masks_test = [], [], []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids_train:\n",
        "\n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks_train.append(att_mask)\n",
        "\n",
        "for sent in input_ids_valid:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks_valid.append(att_mask)\n",
        "\n",
        "for sent in input_ids_test:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks_test.append(att_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## 3.5. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "outputs": [],
      "source": [
        "train_inputs, validation_inputs, test_inpputs, train_labels, validation_labels, test_labels =\\\n",
        "input_ids_train, input_ids_valid, input_ids_test, labels_train, labels_val, labels_test\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, test_masks = attention_masks_train, attention_masks_valid, attention_masks_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LzSbTqW9_BR"
      },
      "source": [
        "## 3.6. Converting to PyTorch Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p1uXczp-Je4"
      },
      "source": [
        "Our model expects PyTorch tensors rather than numpy.ndarrays, so convert all of our dataset variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "outputs": [],
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype\n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sjzRT1V0zwm"
      },
      "source": [
        "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task.\n",
        "\n",
        "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
        "\n",
        "Here is the current list of classes provided for fine-tuning:\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "* BertForMaskedLM\n",
        "* BertForNextSentencePrediction\n",
        "* **BertForSequenceClassification** - The one we'll use.\n",
        "* BertForTokenClassification\n",
        "* BertForQuestionAnswering\n",
        "\n",
        "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYitPoE-cjH"
      },
      "source": [
        "\n",
        "\n",
        "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQW9E-bBCRt"
      },
      "source": [
        "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
        "\n",
        "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "baa55ed847294bb3a7c954a53c238d32",
            "c32c896bfdc34392a7ad9e19705063ce",
            "bf865e8dbc534bbd8369dd0f7922d889",
            "3387a402721d49db963b4e008e53fddb",
            "dd3ddfe03dcb41969725890fb0683062",
            "7e89d82b8c9748138d79c28506876171",
            "96e88ebf979042b881d31e5bf447c956",
            "f0e51be70d014af6b935ad0adda4ee37",
            "dee07e9f2f6244f599a7df2e5334caea",
            "3e41eb9e407642e2839dbea2c1d863f3",
            "9f40f478367749d6ba370f73e016891b"
          ]
        },
        "id": "gFsCTp_mporB",
        "outputId": "79205a5a-2961-4215-9682-6e5e179e3670"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at medicalai/ClinicalBERT and are newly initialized: ['embeddings.token_type_embeddings.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.6.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'classifier.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'pooler.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.attention.self.key.bias', 'classifier.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'pooler.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"medicalai/ClinicalBERT\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Jv6c7-HHDW"
      },
      "source": [
        "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
        "\n",
        "In the below cell, I've printed out the names and dimensions of the weights for:\n",
        "\n",
        "1. The embedding layer.\n",
        "2. The first of the twelve transformers.\n",
        "3. The output layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PIiVlDYCtSq",
        "outputId": "2a465b47-e01c-42c2-8ac0-3ef139dfa44e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values:\n",
        "- Batch size: 16, 32  (We chose 32 when creating our DataLoaders).\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5  (We'll use 2e-5).\n",
        "- Number of epochs: 2, 3, 4  (We'll use 4).\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLs72DuMODJO",
        "outputId": "e50bdebb-10bc-409b-f8de-185628579865"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/new-stg/home/banghua/anaconda3/envs/LLM/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 10\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. At each pass we need to:\n",
        "\n",
        "Training loop:\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass.\n",
        "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "Evalution loop:\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress\n",
        "\n",
        "So please read carefully through the comments to get an understanding of what's happening. If you're unfamiliar with pytorch a quick look at some of their [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) will help show you that training loops really involve only a few simple steps; the rest is usually just decoration and logging.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "Helper function for formatting elapsed times.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J-FYdx6nFE_",
        "outputId": "37eeaf71-a4bc-49ed-d908-8a7ff1c1a990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:01:07.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:02:05.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:03:03.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:04:02.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:05:00.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:59.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:58.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:56.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:55.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:53.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:52.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:50.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:49.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:48.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:46.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:45.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:43.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:42.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:40.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:39.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:37.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:36.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:34.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:33.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:31.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:30.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:28.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:27.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:25.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:24.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:22.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:21.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:20.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:18.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:17.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:15.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:14.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:12.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:11.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:39:09.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:40:08.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:41:06.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:42:05.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:43:04.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:44:02.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:45:01.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:45:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:01:52\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:00:59.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:02:56.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:04:53.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:50.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:47.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:44.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:42.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:40.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:39.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:37.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:36.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:35.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:33.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:32.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:30.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:29.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:27.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:26.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:24.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:23.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:21.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:20.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:18.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:17.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:16.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:14.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:13.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:11.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:10.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:08.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:07.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:05.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:04.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:02.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:39:01.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:39:59.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:40:58.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:41:56.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:42:55.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:43:53.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:44:52.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 0:45:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:01:51\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:00:59.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:02:55.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:04:52.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:49.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:46.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:43.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:42.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:40.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:39.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:37.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:36.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:34.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:33.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:31.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:30.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:29.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:27.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:26.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:24.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:23.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:21.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:20.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:18.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:17.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:17.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:16.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:16.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:15.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:14.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:13.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:11.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:10.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:08.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:07.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:39:05.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:40:04.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:41:02.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:42:01.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:42:59.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:43:57.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:44:56.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:45:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:01:51\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:00:59.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:02:56.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:04:53.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:50.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:47.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:44.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:42.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:41.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:39.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:38.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:36.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:35.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:33.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:32.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:30.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:29.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:27.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:26.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:25.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:23.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:22.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:20.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:19.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:17.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:16.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:14.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:13.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:11.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:10.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:08.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:07.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:05.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:03.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:02.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:39:00.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:39:59.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:40:57.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:41:56.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:42:54.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:43:53.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:44:51.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epcoh took: 0:45:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:01:51\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:02:56.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:04:53.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:50.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:47.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:44.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:42.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:41.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:39.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:38.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:36.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:35.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:33.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:32.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:31.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:29.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:27.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:26.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:25.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:23.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:22.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:20.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:19.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:17.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:16.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:14.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:13.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:11.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:10.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:08.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:07.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:05.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:04.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:03.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:39:01.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:40:00.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:40:58.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:41:57.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:42:55.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:43:54.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:44:52.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:45:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:01:51\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:02:55.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:04:52.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:49.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:46.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:43.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:42.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:40.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:39.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:37.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:36.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:34.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:33.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:31.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:30.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:28.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:27.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:25.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:24.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:22.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:21.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:19.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:18.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:16.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:14.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:13.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:11.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:10.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:08.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:07.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:05.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:04.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:02.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:00.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:38:59.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:39:57.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:40:56.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:41:54.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:42:53.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:43:51.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:44:50.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:45:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:01:51\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:00:58.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:02:55.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:04:52.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:49.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:46.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:44.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:43.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:41.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:40.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:38.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:37.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:35.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:34.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:32.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:31.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:29.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:28.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:26.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:25.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:24.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:22.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:21.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:19.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:18.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:17.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:15.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:13.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:12.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:11.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:09.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:08.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:06.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:05.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:03.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:02.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:39:00.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:39:59.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:40:58.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:41:57.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:42:55.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:43:54.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:44:54.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:45:08\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation took: 0:01:51\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:00:59.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:02:56.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:04:53.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:50.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:47.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:44.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:42.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:41.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:39.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:38.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:36.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:35.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:33.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:32.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:30.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:29.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:27.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:26.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:24.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:23.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:21.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:20.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:18.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:17.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:15.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:14.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:12.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:11.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:09.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:08.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:06.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:05.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:03.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:02.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:39:00.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:39:59.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:40:57.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:41:56.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:42:54.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:43:53.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:44:51.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epcoh took: 0:45:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:01:51\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:00:59.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:02:55.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:04:52.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:50.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:47.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:44.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:42.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:41.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:39.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:38.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:36.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:35.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:33.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:32.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:30.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:29.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:27.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:26.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:24.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:23.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:21.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:20.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:19.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:17.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:15.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:14.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:12.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:11.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:09.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:08.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:07.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:05.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:04.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:02.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:39:00.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:39:59.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:40:58.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:41:56.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:42:55.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:43:53.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:44:52.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:45:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:01:51\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of  1,846.    Elapsed: 0:00:59.\n",
            "  Batch    80  of  1,846.    Elapsed: 0:01:57.\n",
            "  Batch   120  of  1,846.    Elapsed: 0:02:56.\n",
            "  Batch   160  of  1,846.    Elapsed: 0:03:54.\n",
            "  Batch   200  of  1,846.    Elapsed: 0:04:53.\n",
            "  Batch   240  of  1,846.    Elapsed: 0:05:51.\n",
            "  Batch   280  of  1,846.    Elapsed: 0:06:50.\n",
            "  Batch   320  of  1,846.    Elapsed: 0:07:48.\n",
            "  Batch   360  of  1,846.    Elapsed: 0:08:47.\n",
            "  Batch   400  of  1,846.    Elapsed: 0:09:45.\n",
            "  Batch   440  of  1,846.    Elapsed: 0:10:44.\n",
            "  Batch   480  of  1,846.    Elapsed: 0:11:42.\n",
            "  Batch   520  of  1,846.    Elapsed: 0:12:41.\n",
            "  Batch   560  of  1,846.    Elapsed: 0:13:39.\n",
            "  Batch   600  of  1,846.    Elapsed: 0:14:38.\n",
            "  Batch   640  of  1,846.    Elapsed: 0:15:36.\n",
            "  Batch   680  of  1,846.    Elapsed: 0:16:35.\n",
            "  Batch   720  of  1,846.    Elapsed: 0:17:33.\n",
            "  Batch   760  of  1,846.    Elapsed: 0:18:32.\n",
            "  Batch   800  of  1,846.    Elapsed: 0:19:30.\n",
            "  Batch   840  of  1,846.    Elapsed: 0:20:29.\n",
            "  Batch   880  of  1,846.    Elapsed: 0:21:27.\n",
            "  Batch   920  of  1,846.    Elapsed: 0:22:26.\n",
            "  Batch   960  of  1,846.    Elapsed: 0:23:24.\n",
            "  Batch 1,000  of  1,846.    Elapsed: 0:24:23.\n",
            "  Batch 1,040  of  1,846.    Elapsed: 0:25:22.\n",
            "  Batch 1,080  of  1,846.    Elapsed: 0:26:20.\n",
            "  Batch 1,120  of  1,846.    Elapsed: 0:27:19.\n",
            "  Batch 1,160  of  1,846.    Elapsed: 0:28:17.\n",
            "  Batch 1,200  of  1,846.    Elapsed: 0:29:16.\n",
            "  Batch 1,240  of  1,846.    Elapsed: 0:30:14.\n",
            "  Batch 1,280  of  1,846.    Elapsed: 0:31:13.\n",
            "  Batch 1,320  of  1,846.    Elapsed: 0:32:11.\n",
            "  Batch 1,360  of  1,846.    Elapsed: 0:33:10.\n",
            "  Batch 1,400  of  1,846.    Elapsed: 0:34:08.\n",
            "  Batch 1,440  of  1,846.    Elapsed: 0:35:07.\n",
            "  Batch 1,480  of  1,846.    Elapsed: 0:36:05.\n",
            "  Batch 1,520  of  1,846.    Elapsed: 0:37:04.\n",
            "  Batch 1,560  of  1,846.    Elapsed: 0:38:03.\n",
            "  Batch 1,600  of  1,846.    Elapsed: 0:39:01.\n",
            "  Batch 1,640  of  1,846.    Elapsed: 0:40:00.\n",
            "  Batch 1,680  of  1,846.    Elapsed: 0:40:58.\n",
            "  Batch 1,720  of  1,846.    Elapsed: 0:41:57.\n",
            "  Batch 1,760  of  1,846.    Elapsed: 0:42:55.\n",
            "  Batch 1,800  of  1,846.    Elapsed: 0:43:54.\n",
            "  Batch 1,840  of  1,846.    Elapsed: 0:44:52.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:45:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:01:52\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "model_path = os.path.expanduser('~/med264/models/')\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    # Save the model\n",
        "    model.save_pretrained(model_path + str(epoch_i))\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save loss_values\n",
        "with open(model_path + 'loss_values.pickle', 'wb') as f:\n",
        "    pickle.dump(loss_values, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Let's take a look at our training loss over all batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "68xreA9JAmG5",
        "outputId": "7e4cc7cc-1327-47da-dae3-6095fce65551"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# Save the plot to file.\n",
        "plt.savefig(\"BERT_Fine_Tuning_Sentence_Classification_v2_loss.png\", dpi = 300)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save ipynb session\n",
        "import dill\n",
        "dill.dump_session('BERT_Fine_Tuning_Sentence_Classification_v2.db')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:LLM]",
      "language": "python",
      "name": "conda-env-LLM-py"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02c860af048a48039571df1ac10703a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1f85d855dc54d93b07370119c3fb96b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6ce09be5acce441494710b3c0cbc6169",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.78kB/s]"
          }
        },
        "03eb5cad0dd745feb519ae16bc13afd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b16898863445b485e301b75b1c918c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7fada7d50b514b38ad70fa3baf613c6f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1b80d80718874a95b805bca384538f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318e7d7d83c447a793316c7dda14a06d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf4b37cd06c34b6c995b02e30003ff38",
            "value": 466062
          }
        },
        "261c73d7337e4fd89c5512fd7cc801b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99320230aa154969ac7efcb4bd08e93a",
              "IPY_MODEL_1b80d80718874a95b805bca384538f9f",
              "IPY_MODEL_f1fb5bd99db34449aaa0775649c33ade"
            ],
            "layout": "IPY_MODEL_faa00d6df14a4229b40388dbf79b911f"
          }
        },
        "318e7d7d83c447a793316c7dda14a06d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3259bbb9cfbf4652944d6a63779c8536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03eb5cad0dd745feb519ae16bc13afd5",
              "IPY_MODEL_ab7f43db105a4c059816b83b8e3050ec",
              "IPY_MODEL_02c860af048a48039571df1ac10703a0"
            ],
            "layout": "IPY_MODEL_3276e0075f924285aaa17252d34217ba"
          }
        },
        "3276e0075f924285aaa17252d34217ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3387a402721d49db963b4e008e53fddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e41eb9e407642e2839dbea2c1d863f3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9f40f478367749d6ba370f73e016891b",
            "value": " 440M/440M [00:05&lt;00:00, 41.9MB/s]"
          }
        },
        "338a08d6c85e48e0b8ef1c0a083043fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55d9d13ce82b4950a54b33bb6733ea58",
              "IPY_MODEL_8ae18003614946a4b0cb39b81f5a6063",
              "IPY_MODEL_427bed3eb7e743f387a0dd6c23f031e9"
            ],
            "layout": "IPY_MODEL_632c81708e674a61b848d1fccab30084"
          }
        },
        "3496eb8998e64a38bf2ea922eec5f093": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e41eb9e407642e2839dbea2c1d863f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4171dca739984eb68291b7e8f337f372": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ba494ceeba44de99f69891d4fcfed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "427bed3eb7e743f387a0dd6c23f031e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9348b3637d2a4d2088281c8e34d98f3e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_41ba494ceeba44de99f69891d4fcfed7",
            "value": " 570/570 [00:00&lt;00:00, 38.0kB/s]"
          }
        },
        "4ae1954f09a04e0cb50a01a0154f64ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bb4b4d8abb34ffbafa2194402d755f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94d9470c01bd419dbf9f55fa69487ac9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4ae1954f09a04e0cb50a01a0154f64ec",
            "value": " 232k/232k [00:00&lt;00:00, 4.74MB/s]"
          }
        },
        "52b73c5ed8354070bbc22b6b74bde680": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d9d13ce82b4950a54b33bb6733ea58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec7c4858c9be4d359b77d390c432dbbb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_599f7a8f19874431bd445deda4c7b273",
            "value": "config.json: 100%"
          }
        },
        "571e6cb89b8d40cbaa812a53f895acdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "599f7a8f19874431bd445deda4c7b273": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "632c81708e674a61b848d1fccab30084": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a2a3be6805048539e68be9c9db64cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ce09be5acce441494710b3c0cbc6169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e89d82b8c9748138d79c28506876171": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fada7d50b514b38ad70fa3baf613c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82b16898863445b485e301b75b1c918c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae18003614946a4b0cb39b81f5a6063": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_571e6cb89b8d40cbaa812a53f895acdc",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a2a3be6805048539e68be9c9db64cc5",
            "value": 570
          }
        },
        "900a26c928b74d668a77dc97cc22995e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9348b3637d2a4d2088281c8e34d98f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942cfc1c25e54f088288dd44c9c708e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d9470c01bd419dbf9f55fa69487ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e88ebf979042b881d31e5bf447c956": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99320230aa154969ac7efcb4bd08e93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b73c5ed8354070bbc22b6b74bde680",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a747919a41ac43ae9baaf22c5654ca02",
            "value": "tokenizer.json: 100%"
          }
        },
        "9b263a3168674657b14223e58611f294": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e02c53a9b05047b0a3bfc9e47735ee43",
              "IPY_MODEL_b15d78f0355e4c55b9ce4480d42bd67c",
              "IPY_MODEL_4bb4b4d8abb34ffbafa2194402d755f8"
            ],
            "layout": "IPY_MODEL_eb60945d776d4b5a92870fa3371471f6"
          }
        },
        "9ed6e953f4d74267a34be03f6b19283a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f40f478367749d6ba370f73e016891b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a747919a41ac43ae9baaf22c5654ca02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7f43db105a4c059816b83b8e3050ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e9766eb48c4db09d5e9ec558802d25",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3496eb8998e64a38bf2ea922eec5f093",
            "value": 28
          }
        },
        "b15d78f0355e4c55b9ce4480d42bd67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4171dca739984eb68291b7e8f337f372",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ed6e953f4d74267a34be03f6b19283a",
            "value": 231508
          }
        },
        "b4e9766eb48c4db09d5e9ec558802d25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baa55ed847294bb3a7c954a53c238d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c32c896bfdc34392a7ad9e19705063ce",
              "IPY_MODEL_bf865e8dbc534bbd8369dd0f7922d889",
              "IPY_MODEL_3387a402721d49db963b4e008e53fddb"
            ],
            "layout": "IPY_MODEL_dd3ddfe03dcb41969725890fb0683062"
          }
        },
        "bf865e8dbc534bbd8369dd0f7922d889": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e51be70d014af6b935ad0adda4ee37",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dee07e9f2f6244f599a7df2e5334caea",
            "value": 440449768
          }
        },
        "c32c896bfdc34392a7ad9e19705063ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e89d82b8c9748138d79c28506876171",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_96e88ebf979042b881d31e5bf447c956",
            "value": "model.safetensors: 100%"
          }
        },
        "cf4b37cd06c34b6c995b02e30003ff38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd3ddfe03dcb41969725890fb0683062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee07e9f2f6244f599a7df2e5334caea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e02c53a9b05047b0a3bfc9e47735ee43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7286cb5f4e4afdb9b8403265e51f0c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fefd62e5e0064bb6a8ed1f750309b8a1",
            "value": "vocab.txt: 100%"
          }
        },
        "e1f85d855dc54d93b07370119c3fb96b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb60945d776d4b5a92870fa3371471f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec7c4858c9be4d359b77d390c432dbbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0e51be70d014af6b935ad0adda4ee37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1fb5bd99db34449aaa0775649c33ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_942cfc1c25e54f088288dd44c9c708e9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_900a26c928b74d668a77dc97cc22995e",
            "value": " 466k/466k [00:00&lt;00:00, 22.6MB/s]"
          }
        },
        "faa00d6df14a4229b40388dbf79b911f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fefd62e5e0064bb6a8ed1f750309b8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff7286cb5f4e4afdb9b8403265e51f0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
