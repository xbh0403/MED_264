{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning Tutorial with PyTorch\n",
        "\n",
        "By Chris McCormick and Nick Ryan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPgpITmdwvX0"
      },
      "source": [
        "*Revised on 12/13/19 to use the new [transformers](https://github.com/huggingface/transformers) interface.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## 1.1. Using Colab GPU for Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "\n",
        "Google Colab offers free GPUs and TPUs! Since we'll be training a large neural network it's best to take advantage of this (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
        "\n",
        "A GPU can be added by going to the menu and selecting:\n",
        "\n",
        "`Edit ðŸ¡’ Notebook Settings ðŸ¡’ Hardware accelerator ðŸ¡’ (GPU)`\n",
        "\n",
        "Then run the following cell to confirm that the GPU is detected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYsV4H8fCpZ-",
        "outputId": "bac79307-973d-449b-c229-80a22ee613c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/new-stg/home/banghua/anaconda3/envs/LLM/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA RTX A6000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "## 1.2. Installing the Hugging Face Library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N2UDLevYWn"
      },
      "source": [
        "\n",
        "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
        "\n",
        "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
        "\n",
        "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxddqmruamSj"
      },
      "source": [
        "The code in this notebook is actually a simplified version of the [run_glue.py](https://github.com/huggingface/transformers/blob/master/examples/run_glue.py) example script from huggingface.\n",
        "\n",
        "`run_glue.py` is a helpful utility which allows you to pick which GLUE benchmark task you want to run on, and which pre-trained model you want to use (you can see the list of possible models [here](https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69)). It also supports using either the CPU, a single GPU, or multiple GPUs. It even supports using 16-bit precision if you want further speed up.\n",
        "\n",
        "Unfortunately, all of this configurability comes at the cost of *readability*. In this Notebook, we've simplified the code greatly and added plenty of comments to make it clear what's going on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# 2. Loading CoLA Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## 2.2. Parse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeyVCXT31EZQ"
      },
      "source": [
        "We can see from the file names that both `tokenized` and `raw` versions of the data are available.\n",
        "\n",
        "We can't use the pre-tokenized version because, in order to apply the pre-trained BERT, we *must* use the tokenizer provided by the model. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "_UkeC7SG2krJ",
        "outputId": "83fcecd4-b718-4bc8-9026-e6d1151d83a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training sentences: 26,108\n",
            "\n",
            "Number of validation sentences: 3,100\n",
            "\n",
            "Number of testing sentences: 3,246\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df_train = pd.read_csv(\"~/med264/Dataset1/day1_30mortality_train.csv\", index_col=0)\n",
        "num_train_pos = df_train[df_train['Label'] == 1].shape[0]\n",
        "num_train_neg = df_train[df_train['Label'] == 0].shape[0]\n",
        "num_balanced = min(num_train_pos, num_train_neg)\n",
        "df_train_pos = df_train[df_train['Label'] == 1].sample(n=num_balanced, random_state=42)\n",
        "df_train_neg = df_train[df_train['Label'] == 0].sample(n=num_balanced, random_state=42)\n",
        "df_train = pd.concat([df_train_pos, df_train_neg])\n",
        "\n",
        "df_val = pd.read_csv(\"~/med264/Dataset1/day1_30mortality_val.csv\", index_col=0)\n",
        "num_val_pos = df_val[df_val['Label'] == 1].shape[0]\n",
        "num_val_neg = df_val[df_val['Label'] == 0].shape[0]\n",
        "num_balanced = min(num_val_pos, num_val_neg)\n",
        "df_val_pos = df_val[df_val['Label'] == 1].sample(n=num_balanced, random_state=42)\n",
        "df_val_neg = df_val[df_val['Label'] == 0].sample(n=num_balanced, random_state=42)\n",
        "df_val = pd.concat([df_val_pos, df_val_neg])\n",
        "\n",
        "df_test = pd.read_csv(\"~/med264/Dataset1/day1_30mortality_test.csv\", index_col=0)\n",
        "num_test_pos = df_test[df_test['Label'] == 1].shape[0]\n",
        "num_test_neg = df_test[df_test['Label'] == 0].shape[0]\n",
        "num_balanced = min(num_test_pos, num_test_neg)\n",
        "df_test_pos = df_test[df_test['Label'] == 1].sample(n=num_balanced, random_state=42)\n",
        "df_test_neg = df_test[df_test['Label'] == 0].sample(n=num_balanced, random_state=42)\n",
        "df_test = pd.concat([df_test_pos, df_test_neg])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df_train.shape[0]))\n",
        "print('Number of validation sentences: {:,}\\n'.format(df_val.shape[0]))\n",
        "print('Number of testing sentences: {:,}\\n'.format(df_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "outputs": [],
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences_train = df_train.TEXT.values\n",
        "labels_train = df_train.Label.values\n",
        "sentences_val = df_val.TEXT.values\n",
        "labels_val = df_val.Label.values\n",
        "sentences_test = df_test.TEXT.values\n",
        "labels_test = df_test.Label.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "3259bbb9cfbf4652944d6a63779c8536",
            "03eb5cad0dd745feb519ae16bc13afd5",
            "ab7f43db105a4c059816b83b8e3050ec",
            "02c860af048a48039571df1ac10703a0",
            "3276e0075f924285aaa17252d34217ba",
            "82b16898863445b485e301b75b1c918c",
            "7fada7d50b514b38ad70fa3baf613c6f",
            "b4e9766eb48c4db09d5e9ec558802d25",
            "3496eb8998e64a38bf2ea922eec5f093",
            "e1f85d855dc54d93b07370119c3fb96b",
            "6ce09be5acce441494710b3c0cbc6169",
            "9b263a3168674657b14223e58611f294",
            "e02c53a9b05047b0a3bfc9e47735ee43",
            "b15d78f0355e4c55b9ce4480d42bd67c",
            "4bb4b4d8abb34ffbafa2194402d755f8",
            "eb60945d776d4b5a92870fa3371471f6",
            "ff7286cb5f4e4afdb9b8403265e51f0c",
            "fefd62e5e0064bb6a8ed1f750309b8a1",
            "4171dca739984eb68291b7e8f337f372",
            "9ed6e953f4d74267a34be03f6b19283a",
            "94d9470c01bd419dbf9f55fa69487ac9",
            "4ae1954f09a04e0cb50a01a0154f64ec",
            "261c73d7337e4fd89c5512fd7cc801b9",
            "99320230aa154969ac7efcb4bd08e93a",
            "1b80d80718874a95b805bca384538f9f",
            "f1fb5bd99db34449aaa0775649c33ade",
            "faa00d6df14a4229b40388dbf79b911f",
            "52b73c5ed8354070bbc22b6b74bde680",
            "a747919a41ac43ae9baaf22c5654ca02",
            "318e7d7d83c447a793316c7dda14a06d",
            "cf4b37cd06c34b6c995b02e30003ff38",
            "942cfc1c25e54f088288dd44c9c708e9",
            "900a26c928b74d668a77dc97cc22995e",
            "338a08d6c85e48e0b8ef1c0a083043fb",
            "55d9d13ce82b4950a54b33bb6733ea58",
            "8ae18003614946a4b0cb39b81f5a6063",
            "427bed3eb7e743f387a0dd6c23f031e9",
            "632c81708e674a61b848d1fccab30084",
            "ec7c4858c9be4d359b77d390c432dbbb",
            "599f7a8f19874431bd445deda4c7b273",
            "571e6cb89b8d40cbaa812a53f895acdc",
            "6a2a3be6805048539e68be9c9db64cc5",
            "9348b3637d2a4d2088281c8e34d98f3e",
            "41ba494ceeba44de99f69891d4fcfed7"
          ]
        },
        "id": "Z474sSC6oe7A",
        "outputId": "98043c48-fe54-4d6f-ff35-ac3d33ee28d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
            "The class this function is called from is 'BertTokenizer'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('medicalai/ClinicalBERT', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLIbudgfh6F0",
        "outputId": "a07b82c7-99cc-41db-e017-1ba73c3537c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Original:  throughout the aorta. there is no hilar, mediastinal, or axillary lymphadenopathy. ct of the abdomen with iv contrast: ng tube is noted within the stomach. the adrenal glands, pancreas, gallbladder, and liver are within normal limits. there is a small splenic cyst near the splenic hilum. the kidneys are shrunken and atrophic bilaterally. multiple cysts are noted with the largest in the right kidney measuring up to 6 cm. there is no retroperitoneal or mesenteric lymphadenopathy. there is no free air or free fluid. (over) 1:44 pm cta chest w&w/o c&recons, non-coronary; ct abdomen w/contrast clip # ct pelvis w/contrast reason: r/o pe final report (cont) ct of the pelvis with iv contrast: the rectum and sigmoid colon are abnormal with wall thickening, adjacent fat stranding, and relative of the wall. the remainder of the bowel wall appears within normal limits. there is no evidence of obstruction. the abdominal and pelvic arterial vasculature is heavily calcified. however, there is no evidence of filling defect within the arterial vasculature. a foley catheter is within a nearly decompressed bladder. the prostate is markedly enlarged with a prostatic stent. the stent remains in the prostate. the foley catheter is inflated within the prostate proximal to the stent. the tip of the foley catheter is external to the lumen of the stent, ending along the outer, posterior edge there are small bilateral fat-containing inguinal hernias. there is no pelvic or inguinal lymphadenopathy. bone windows: no concerning osseous lesions are identified. impression: no evidence of pulmonary embolism or dissection. aneurysm of the ascending aorta. trace pericardial fluid. dilated, ahaustral, and hypoenhancing segments of the sigmoid colon with bowel wall thickening and adjacent fat stranding, concerning for infectious process, less likely ischemia. enlarged prostate with prostatic stent. foley catheter ends proximal to stent with balloon inflated within the prostate. small atrophic bilateral kidneys. findings were discussed with doctor shortly after review on . revised\n",
            "Tokenized:  ['throughout', 'the', 'ao', '##rta', '.', 'there', 'is', 'no', 'hil', '##ar', ',', 'medias', '##tina', '##l', ',', 'or', 'a', '##xi', '##llar', '##y', 'ly', '##mp', '##had', '##eno', '##pat', '##hy', '.', 'c', '##t', 'of', 'the', 'abdomen', 'with', 'i', '##v', 'contrast', ':', 'ng', 'tube', 'is', 'noted', 'within', 'the', 'sto', '##mach', '.', 'the', 'ad', '##rena', '##l', 'g', '##lands', ',', 'pan', '##cre', '##as', ',', 'gall', '##blad', '##der', ',', 'and', 'liver', 'are', 'within', 'normal', 'limits', '.', 'there', 'is', 'a', 'small', 'sp', '##leni', '##c', 'c', '##yst', 'near', 'the', 'sp', '##leni', '##c', 'hil', '##um', '.', 'the', 'ki', '##dne', '##ys', 'are', 'sh', '##runk', '##en', 'and', 'at', '##rop', '##hic', 'bila', '##teral', '##ly', '.', 'multiple', 'c', '##yst', '##s', 'are', 'noted', 'with', 'the', 'largest', 'in', 'the', 'right', 'ki', '##dne', '##y', 'measuring', 'up', 'to', '6', 'cm', '.', 'there', 'is', 'no', 'ret', '##rop', '##erit', '##one', '##al', 'or', 'mese', '##nter', '##ic', 'ly', '##mp', '##had', '##eno', '##pat', '##hy', '.', 'there', 'is', 'no', 'free', 'air', 'or', 'free', 'fluid', '.', '(', 'over', ')', '1', ':', '44', 'pm', 'c', '##ta', 'chest', 'w', '&', 'w', '/', 'o', 'c', '&', 're', '##cons', ',', 'non', '-', 'corona', '##ry', ';', 'c', '##t', 'abdomen', 'w', '/', 'contrast', 'clip', '#', 'c', '##t', 'pel', '##vis', 'w', '/', 'contrast', 'reason', ':', 'r', '/', 'o', 'pe', 'final', 'report', '(', 'cont', ')', 'c', '##t', 'of', 'the', 'pel', '##vis', 'with', 'i', '##v', 'contrast', ':', 'the', 're', '##ctum', 'and', 'sig', '##mo', '##id', 'col', '##on', 'are', 'ab', '##normal', 'with', 'wall', 'thick', '##ening', ',', 'adjacent', 'fat', 'strand', '##ing', ',', 'and', 'relative', 'of', 'the', 'wall', '.', 'the', 'remainder', 'of', 'the', 'bow', '##el', 'wall', 'appears', 'within', 'normal', 'limits', '.', 'there', 'is', 'no', 'evidence', 'of', 'ob', '##stru', '##ction', '.', 'the', 'ab', '##dom', '##inal', 'and', 'pel', '##vic', 'arteria', '##l', 'vas', '##cula', '##ture', 'is', 'heavily', 'cal', '##ci', '##fied', '.', 'however', ',', 'there', 'is', 'no', 'evidence', 'of', 'fill', '##ing', 'def', '##ect', 'within', 'the', 'arteria', '##l', 'vas', '##cula', '##ture', '.', 'a', 'f', '##ole', '##y', 'cat', '##heter', 'is', 'within', 'a', 'nearly', 'de', '##com', '##pressed', 'blad', '##der', '.', 'the', 'pro', '##state', 'is', 'marked', '##ly', 'enlarged', 'with', 'a', 'pro', '##stati', '##c', 'st', '##ent', '.', 'the', 'st', '##ent', 'remains', 'in', 'the', 'pro', '##state', '.', 'the', 'f', '##ole', '##y', 'cat', '##heter', 'is', 'in', '##f', '##lated', 'within', 'the', 'pro', '##state', 'pro', '##xima', '##l', 'to', 'the', 'st', '##ent', '.', 'the', 'tip', 'of', 'the', 'f', '##ole', '##y', 'cat', '##heter', 'is', 'external', 'to', 'the', 'lume', '##n', 'of', 'the', 'st', '##ent', ',', 'ending', 'along', 'the', 'outer', ',', 'posterior', 'edge', 'there', 'are', 'small', 'bila', '##teral', 'fat', '-', 'containing', 'ing', '##uin', '##al', 'her', '##nia', '##s', '.', 'there', 'is', 'no', 'pel', '##vic', 'or', 'ing', '##uin', '##al', 'ly', '##mp', '##had', '##eno', '##pat', '##hy', '.', 'bone', 'windows', ':', 'no', 'concerning', 'oss', '##eo', '##us', 'les', '##ions', 'are', 'identified', '.', 'impression', ':', 'no', 'evidence', 'of', 'pu', '##lm', '##onar', '##y', 'em', '##bolism', 'or', 'disse', '##ction', '.', 'ane', '##ury', '##sm', 'of', 'the', 'as', '##cend', '##ing', 'ao', '##rta', '.', 'trace', 'per', '##ica', '##rdia', '##l', 'fluid', '.', 'dil', '##ated', ',', 'ah', '##aust', '##ral', ',', 'and', 'hy', '##po', '##en', '##han', '##cing', 'segments', 'of', 'the', 'sig', '##mo', '##id', 'col', '##on', 'with', 'bow', '##el', 'wall', 'thick', '##ening', 'and', 'adjacent', 'fat', 'strand', '##ing', ',', 'concerning', 'for', 'in', '##fect', '##ious', 'process', ',', 'less', 'likely', 'is', '##chem', '##ia', '.', 'enlarged', 'pro', '##state', 'with', 'pro', '##stati', '##c', 'st', '##ent', '.', 'f', '##ole', '##y', 'cat', '##heter', 'ends', 'pro', '##xima', '##l', 'to', 'st', '##ent', 'with', 'ball', '##oon', 'in', '##f', '##lated', 'within', 'the', 'pro', '##state', '.', 'small', 'at', '##rop', '##hic', 'bila', '##teral', 'ki', '##dne', '##ys', '.', 'findings', 'were', 'discussed', 'with', 'doctor', 'shortly', 'after', 'review', 'on', '.', 'revised']\n",
            "Token IDs:  [15916, 10105, 10610, 16294, 119, 11155, 10124, 10192, 48989, 10354, 117, 105901, 18515, 10161, 117, 10345, 169, 20572, 37203, 10157, 66003, 18573, 33796, 16818, 18115, 19275, 119, 171, 10123, 10108, 10105, 94614, 10169, 177, 10477, 34001, 131, 10743, 45245, 10124, 18575, 12381, 10105, 47264, 68388, 119, 10105, 10840, 37816, 10161, 175, 18425, 117, 24960, 27794, 10403, 117, 60282, 37538, 11304, 117, 10111, 93160, 10301, 12381, 16626, 47418, 119, 11155, 10124, 169, 12474, 32650, 81635, 10350, 171, 62769, 12883, 10105, 32650, 81635, 10350, 48989, 10465, 119, 10105, 10879, 20714, 12682, 10301, 48201, 110034, 10136, 10111, 10160, 30698, 39187, 12517, 98161, 10454, 119, 19865, 171, 62769, 10107, 10301, 18575, 10169, 10105, 15363, 10106, 10105, 13448, 10879, 20714, 10157, 92267, 10741, 10114, 127, 11207, 119, 11155, 10124, 10192, 62893, 30698, 101493, 12926, 10415, 10345, 34182, 25446, 11130, 66003, 18573, 33796, 16818, 18115, 19275, 119, 11155, 10124, 10192, 13961, 12566, 10345, 13961, 59848, 119, 113, 10491, 114, 122, 131, 11126, 52160, 171, 10213, 94230, 191, 111, 191, 120, 183, 171, 111, 11639, 69013, 117, 10446, 118, 31206, 10908, 132, 171, 10123, 94614, 191, 120, 34001, 48545, 108, 171, 10123, 12493, 13844, 191, 120, 34001, 27949, 131, 186, 120, 183, 11161, 11070, 17553, 113, 60146, 114, 171, 10123, 10108, 10105, 12493, 13844, 10169, 177, 10477, 34001, 131, 10105, 11639, 95745, 10111, 11546, 11033, 11249, 12678, 10263, 10301, 11357, 89304, 10169, 26699, 59925, 24428, 117, 32018, 67952, 65803, 10230, 117, 10111, 25315, 10108, 10105, 26699, 119, 10105, 50308, 10108, 10105, 98073, 10570, 26699, 20296, 12381, 16626, 47418, 119, 11155, 10124, 10192, 18713, 10108, 17339, 42461, 17530, 119, 10105, 11357, 15561, 37476, 10111, 12493, 48175, 108437, 10161, 41924, 32107, 16023, 10124, 33556, 25923, 10598, 19907, 119, 13800, 117, 11155, 10124, 10192, 18713, 10108, 20241, 10230, 100745, 56906, 12381, 10105, 108437, 10161, 41924, 32107, 16023, 119, 169, 174, 20325, 10157, 41163, 33926, 10124, 12381, 169, 21377, 10104, 22530, 96616, 69760, 11304, 119, 10105, 11284, 65023, 10124, 26981, 10454, 108200, 10169, 169, 11284, 70796, 10350, 28780, 11405, 119, 10105, 28780, 11405, 19602, 10106, 10105, 11284, 65023, 119, 10105, 174, 20325, 10157, 41163, 33926, 10124, 10106, 10575, 50476, 12381, 10105, 11284, 65023, 11284, 104686, 10161, 10114, 10105, 28780, 11405, 119, 10105, 25119, 10108, 10105, 174, 20325, 10157, 41163, 33926, 10124, 44915, 10114, 10105, 65911, 10115, 10108, 10105, 28780, 11405, 117, 29077, 12400, 10105, 52092, 117, 22658, 30599, 11155, 10301, 12474, 12517, 98161, 67952, 118, 27248, 11600, 26718, 10415, 10485, 11335, 10107, 119, 11155, 10124, 10192, 12493, 48175, 10345, 11600, 26718, 10415, 66003, 18573, 33796, 16818, 18115, 19275, 119, 57254, 40115, 131, 10192, 53047, 92209, 15998, 10251, 10152, 15880, 10301, 26121, 119, 59513, 131, 10192, 18713, 10108, 34597, 55183, 44320, 10157, 10266, 108525, 10345, 15718, 17530, 119, 46226, 35567, 19534, 10108, 10105, 10146, 89387, 10230, 10610, 16294, 119, 59963, 10178, 11043, 45157, 10161, 59848, 119, 36031, 22525, 117, 69863, 71794, 13600, 117, 10111, 15165, 13520, 10136, 11781, 19113, 58202, 10108, 10105, 11546, 11033, 11249, 12678, 10263, 10169, 98073, 10570, 26699, 59925, 24428, 10111, 32018, 67952, 65803, 10230, 117, 53047, 10142, 10106, 84732, 25087, 15138, 117, 15306, 22497, 10124, 34884, 10280, 119, 108200, 11284, 65023, 10169, 11284, 70796, 10350, 28780, 11405, 119, 174, 20325, 10157, 41163, 33926, 29047, 11284, 104686, 10161, 10114, 28780, 11405, 10169, 20724, 15938, 10106, 10575, 50476, 12381, 10105, 11284, 65023, 119, 12474, 10160, 30698, 39187, 12517, 98161, 10879, 20714, 12682, 119, 79441, 10309, 55424, 10169, 26937, 31555, 10662, 17030, 10135, 119, 41226]\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences_train[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeNIc4auFUdF"
      },
      "source": [
        "When we actually convert all of our sentences, we'll use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately.\n",
        "\n",
        "Before we can do that, though, we need to talk about some of BERT's formatting requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ"
      },
      "source": [
        "## 3.2. Sentences to IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M296yz577fV"
      },
      "source": [
        "The `tokenizer.encode` function combines multiple steps for us:\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "\n",
        "Oddly, this function can perform truncating for us, but doesn't handle padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bBdb3pt8LuQ",
        "outputId": "11ab1ae6-cc86-489b-b697-1606b4d990f4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26108/26108 [01:43<00:00, 251.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved input_ids_train.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3100/3100 [00:11<00:00, 262.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved input_ids_valid.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3246/3246 [00:14<00:00, 225.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved input_ids_test.\n",
            "Original:  throughout the aorta. there is no hilar, mediastinal, or axillary lymphadenopathy. ct of the abdomen with iv contrast: ng tube is noted within the stomach. the adrenal glands, pancreas, gallbladder, and liver are within normal limits. there is a small splenic cyst near the splenic hilum. the kidneys are shrunken and atrophic bilaterally. multiple cysts are noted with the largest in the right kidney measuring up to 6 cm. there is no retroperitoneal or mesenteric lymphadenopathy. there is no free air or free fluid. (over) 1:44 pm cta chest w&w/o c&recons, non-coronary; ct abdomen w/contrast clip # ct pelvis w/contrast reason: r/o pe final report (cont) ct of the pelvis with iv contrast: the rectum and sigmoid colon are abnormal with wall thickening, adjacent fat stranding, and relative of the wall. the remainder of the bowel wall appears within normal limits. there is no evidence of obstruction. the abdominal and pelvic arterial vasculature is heavily calcified. however, there is no evidence of filling defect within the arterial vasculature. a foley catheter is within a nearly decompressed bladder. the prostate is markedly enlarged with a prostatic stent. the stent remains in the prostate. the foley catheter is inflated within the prostate proximal to the stent. the tip of the foley catheter is external to the lumen of the stent, ending along the outer, posterior edge there are small bilateral fat-containing inguinal hernias. there is no pelvic or inguinal lymphadenopathy. bone windows: no concerning osseous lesions are identified. impression: no evidence of pulmonary embolism or dissection. aneurysm of the ascending aorta. trace pericardial fluid. dilated, ahaustral, and hypoenhancing segments of the sigmoid colon with bowel wall thickening and adjacent fat stranding, concerning for infectious process, less likely ischemia. enlarged prostate with prostatic stent. foley catheter ends proximal to stent with balloon inflated within the prostate. small atrophic bilateral kidneys. findings were discussed with doctor shortly after review on . revised\n",
            "Token IDs: [101, 15916, 10105, 10610, 16294, 119, 11155, 10124, 10192, 48989, 10354, 117, 105901, 18515, 10161, 117, 10345, 169, 20572, 37203, 10157, 66003, 18573, 33796, 16818, 18115, 19275, 119, 171, 10123, 10108, 10105, 94614, 10169, 177, 10477, 34001, 131, 10743, 45245, 10124, 18575, 12381, 10105, 47264, 68388, 119, 10105, 10840, 37816, 10161, 175, 18425, 117, 24960, 27794, 10403, 117, 60282, 37538, 11304, 117, 10111, 93160, 10301, 12381, 16626, 47418, 119, 11155, 10124, 169, 12474, 32650, 81635, 10350, 171, 62769, 12883, 10105, 32650, 81635, 10350, 48989, 10465, 119, 10105, 10879, 20714, 12682, 10301, 48201, 110034, 10136, 10111, 10160, 30698, 39187, 12517, 98161, 10454, 119, 19865, 171, 62769, 10107, 10301, 18575, 10169, 10105, 15363, 10106, 10105, 13448, 10879, 20714, 10157, 92267, 10741, 10114, 127, 11207, 119, 11155, 10124, 10192, 62893, 30698, 101493, 12926, 10415, 10345, 34182, 25446, 11130, 66003, 18573, 33796, 16818, 18115, 19275, 119, 11155, 10124, 10192, 13961, 12566, 10345, 13961, 59848, 119, 113, 10491, 114, 122, 131, 11126, 52160, 171, 10213, 94230, 191, 111, 191, 120, 183, 171, 111, 11639, 69013, 117, 10446, 118, 31206, 10908, 132, 171, 10123, 94614, 191, 120, 34001, 48545, 108, 171, 10123, 12493, 13844, 191, 120, 34001, 27949, 131, 186, 120, 183, 11161, 11070, 17553, 113, 60146, 114, 171, 10123, 10108, 10105, 12493, 13844, 10169, 177, 10477, 34001, 131, 10105, 11639, 95745, 10111, 11546, 11033, 11249, 12678, 10263, 10301, 11357, 89304, 10169, 26699, 59925, 24428, 117, 32018, 67952, 65803, 10230, 117, 10111, 25315, 10108, 10105, 26699, 119, 10105, 50308, 10108, 10105, 98073, 10570, 26699, 20296, 12381, 16626, 47418, 119, 11155, 10124, 10192, 18713, 10108, 17339, 42461, 17530, 119, 10105, 11357, 15561, 37476, 10111, 12493, 48175, 108437, 10161, 41924, 32107, 16023, 10124, 33556, 25923, 10598, 19907, 119, 13800, 117, 11155, 10124, 10192, 18713, 10108, 20241, 10230, 100745, 56906, 12381, 10105, 108437, 10161, 41924, 32107, 16023, 119, 169, 174, 20325, 10157, 41163, 33926, 10124, 12381, 169, 21377, 10104, 22530, 96616, 69760, 11304, 119, 10105, 11284, 65023, 10124, 26981, 10454, 108200, 10169, 169, 11284, 70796, 10350, 28780, 11405, 119, 10105, 28780, 11405, 19602, 10106, 10105, 11284, 65023, 119, 10105, 174, 20325, 10157, 41163, 33926, 10124, 10106, 10575, 50476, 12381, 10105, 11284, 65023, 11284, 104686, 10161, 10114, 10105, 28780, 11405, 119, 10105, 25119, 10108, 10105, 174, 20325, 10157, 41163, 33926, 10124, 44915, 10114, 10105, 65911, 10115, 10108, 10105, 28780, 11405, 117, 29077, 12400, 10105, 52092, 117, 22658, 30599, 11155, 10301, 12474, 12517, 98161, 67952, 118, 27248, 11600, 26718, 10415, 10485, 11335, 10107, 119, 11155, 10124, 10192, 12493, 48175, 10345, 11600, 26718, 10415, 66003, 18573, 33796, 16818, 18115, 19275, 119, 57254, 40115, 131, 10192, 53047, 92209, 15998, 10251, 10152, 15880, 10301, 26121, 119, 59513, 131, 10192, 18713, 10108, 34597, 55183, 44320, 10157, 10266, 108525, 10345, 15718, 17530, 119, 46226, 35567, 19534, 10108, 10105, 10146, 89387, 10230, 10610, 16294, 119, 59963, 10178, 11043, 45157, 10161, 59848, 119, 36031, 22525, 117, 69863, 71794, 13600, 117, 10111, 15165, 13520, 10136, 11781, 19113, 58202, 10108, 10105, 11546, 11033, 11249, 12678, 10263, 10169, 98073, 10570, 26699, 59925, 24428, 10111, 32018, 67952, 65803, 10230, 117, 53047, 10142, 10106, 84732, 25087, 15138, 117, 15306, 22497, 10124, 34884, 10280, 119, 108200, 11284, 65023, 10169, 11284, 70796, 10350, 28780, 11405, 119, 174, 20325, 10157, 41163, 33926, 29047, 11284, 104686, 10161, 10114, 28780, 11405, 10169, 20724, 15938, 10106, 10575, 50476, 12381, 10105, 11284, 65023, 119, 12474, 10160, 30698, 39187, 12517, 98161, 10879, 20714, 12682, 119, 79441, 10309, 55424, 10169, 26937, 31555, 10662, 17030, 10135, 119, 41226, 102]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Correct the path by expanding the tilde to the user's home directory\n",
        "file_path_train = os.path.expanduser('~/med264/Dataset2/input_ids_train.pickle')\n",
        "file_path_valid = os.path.expanduser('~/med264/Dataset2/input_ids_valid.pickle')\n",
        "file_path_test = os.path.expanduser('~/med264/Dataset2/input_ids_test.pickle')\n",
        "\n",
        "\n",
        "input_ids_train, input_ids_valid, input_ids_test = [], [], []\n",
        "\n",
        "if os.path.exists(file_path_train):\n",
        "    with open(file_path_train, 'rb') as f:\n",
        "        input_ids_train = pickle.load(f)\n",
        "    print('Loaded input_ids_train.')\n",
        "else:\n",
        "    for sent in tqdm(sentences_train):\n",
        "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
        "        input_ids_train.append(encoded_sent)\n",
        "    with open(file_path_train, 'wb') as f:\n",
        "        pickle.dump(input_ids_train, f)\n",
        "    print('Saved input_ids_train.')\n",
        "\n",
        "\n",
        "if os.path.exists(file_path_valid):\n",
        "    with open(file_path_valid, 'rb') as f:\n",
        "        input_ids_valid = pickle.load(f)\n",
        "    print('Loaded input_ids_valid.')\n",
        "else:\n",
        "    for sent in tqdm(sentences_val):\n",
        "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
        "        input_ids_valid.append(encoded_sent)\n",
        "    with open(file_path_valid, 'wb') as f:\n",
        "        pickle.dump(input_ids_valid, f)\n",
        "    print('Saved input_ids_valid.')\n",
        "\n",
        "if os.path.exists(file_path_test):\n",
        "    with open(file_path_test, 'rb') as f:\n",
        "        input_ids_test = pickle.load(f)\n",
        "    print('Loaded input_ids_test.')\n",
        "else:\n",
        "    for sent in tqdm(sentences_test):\n",
        "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
        "        input_ids_test.append(encoded_sent)\n",
        "    with open(file_path_test, 'wb') as f:\n",
        "            pickle.dump(input_ids_test, f)\n",
        "    print('Saved input_ids_test.')\n",
        "    \n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences_train[0])\n",
        "print('Token IDs:', input_ids_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhwCKszh6ych"
      },
      "source": [
        "## 3.3. Padding & Truncating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytsw1oIfnX0"
      },
      "source": [
        "Pad and truncate our sequences so that they all have the same length, `MAX_LEN`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqiWTDrn_nGB"
      },
      "source": [
        "First, what's the maximum sentence length in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhUZO9vc_l6T",
        "outputId": "3962e62a-f572-43ff-ac22-6ae8fa01ad0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max train sentence length:  918\n",
            "Max valid sentence length:  1123\n",
            "Max test sentence length:  878\n"
          ]
        }
      ],
      "source": [
        "print('Max train sentence length: ', max([len(sen) for sen in input_ids_train]))\n",
        "print('Max valid sentence length: ', max([len(sen) for sen in input_ids_valid]))\n",
        "print('Max test sentence length: ', max([len(sen) for sen in input_ids_test]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp-54FcQ_p3h"
      },
      "source": [
        "Given that, let's choose MAX_LEN = 64 and apply the padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp9BPRd1tMIo",
        "outputId": "7530cd63-5916-4bee-dad5-f5533faf5aa5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-28 01:50:04.981461: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-28 01:50:05.020124: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 01:50:05.020159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 01:50:05.021145: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 01:50:05.026778: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-28 01:50:06.170019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 512 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 512\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "input_ids_valid = pad_sequences(input_ids_valid, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDs-MYtYH8sL"
      },
      "source": [
        "## 3.4. Attention Masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhGulL1pExCT"
      },
      "source": [
        "The attention mask simply makes it explicit which tokens are actual words versus which are padding.\n",
        "\n",
        "The BERT vocabulary does not use the ID 0, so if a token ID is 0, then it's padding, and otherwise it's a real token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cDoC24LeEv3N"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks_train, attention_masks_valid, attention_masks_test = [], [], []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids_train:\n",
        "\n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks_train.append(att_mask)\n",
        "\n",
        "for sent in input_ids_valid:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks_valid.append(att_mask)\n",
        "\n",
        "for sent in input_ids_test:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks_test.append(att_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## 3.5. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "outputs": [],
      "source": [
        "train_inputs, validation_inputs, test_inpputs, train_labels, validation_labels, test_labels =\\\n",
        "input_ids_train, input_ids_valid, input_ids_test, labels_train, labels_val, labels_test\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, test_masks = attention_masks_train, attention_masks_valid, attention_masks_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LzSbTqW9_BR"
      },
      "source": [
        "## 3.6. Converting to PyTorch Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p1uXczp-Je4"
      },
      "source": [
        "Our model expects PyTorch tensors rather than numpy.ndarrays, so convert all of our dataset variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "outputs": [],
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype\n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sjzRT1V0zwm"
      },
      "source": [
        "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task.\n",
        "\n",
        "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
        "\n",
        "Here is the current list of classes provided for fine-tuning:\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "* BertForMaskedLM\n",
        "* BertForNextSentencePrediction\n",
        "* **BertForSequenceClassification** - The one we'll use.\n",
        "* BertForTokenClassification\n",
        "* BertForQuestionAnswering\n",
        "\n",
        "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYitPoE-cjH"
      },
      "source": [
        "\n",
        "\n",
        "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnQW9E-bBCRt"
      },
      "source": [
        "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
        "\n",
        "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "baa55ed847294bb3a7c954a53c238d32",
            "c32c896bfdc34392a7ad9e19705063ce",
            "bf865e8dbc534bbd8369dd0f7922d889",
            "3387a402721d49db963b4e008e53fddb",
            "dd3ddfe03dcb41969725890fb0683062",
            "7e89d82b8c9748138d79c28506876171",
            "96e88ebf979042b881d31e5bf447c956",
            "f0e51be70d014af6b935ad0adda4ee37",
            "dee07e9f2f6244f599a7df2e5334caea",
            "3e41eb9e407642e2839dbea2c1d863f3",
            "9f40f478367749d6ba370f73e016891b"
          ]
        },
        "id": "gFsCTp_mporB",
        "outputId": "79205a5a-2961-4215-9682-6e5e179e3670"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at medicalai/ClinicalBERT and are newly initialized: ['encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'classifier.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'pooler.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'pooler.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'classifier.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"medicalai/ClinicalBERT\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Jv6c7-HHDW"
      },
      "source": [
        "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
        "\n",
        "In the below cell, I've printed out the names and dimensions of the weights for:\n",
        "\n",
        "1. The embedding layer.\n",
        "2. The first of the twelve transformers.\n",
        "3. The output layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PIiVlDYCtSq",
        "outputId": "2a465b47-e01c-42c2-8ac0-3ef139dfa44e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values:\n",
        "- Batch size: 16, 32  (We chose 32 when creating our DataLoaders).\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5  (We'll use 2e-5).\n",
        "- Number of epochs: 2, 3, 4  (We'll use 4).\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLs72DuMODJO",
        "outputId": "e50bdebb-10bc-409b-f8de-185628579865"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/new-stg/home/banghua/anaconda3/envs/LLM/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 10\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. At each pass we need to:\n",
        "\n",
        "Training loop:\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass.\n",
        "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "Evalution loop:\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress\n",
        "\n",
        "So please read carefully through the comments to get an understanding of what's happening. If you're unfamiliar with pytorch a quick look at some of their [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) will help show you that training loops really involve only a few simple steps; the rest is usually just decoration and logging.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "Helper function for formatting elapsed times.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J-FYdx6nFE_",
        "outputId": "37eeaf71-a4bc-49ed-d908-8a7ff1c1a990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch    40  of    408.    Elapsed: 0:00:57.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:55.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:54.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:52.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:51.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:50.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:48.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:47.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:45.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:44.\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epcoh took: 0:10:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.58\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    408.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:56.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:54.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:53.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:51.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:50.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:48.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:47.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:45.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epcoh took: 0:10:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.69\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    408.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:55.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:54.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:53.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:51.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:50.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:48.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:47.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:46.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:10:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    408.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:56.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:54.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:53.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:51.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:50.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:48.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:47.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:45.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:10:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    408.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:56.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:54.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:53.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:51.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:50.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:48.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:47.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:45.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:10:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    408.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:56.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:54.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:53.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:51.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:50.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:48.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:47.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:45.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:10:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    408.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:56.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:54.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:53.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:51.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:50.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:48.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:47.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:46.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:10:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    408.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:55.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:54.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:53.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:51.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:50.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:48.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:47.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:46.\n",
            "\n",
            "  Average training loss: 0.47\n",
            "  Training epcoh took: 0:10:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    408.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:56.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:54.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:53.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:51.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:50.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:48.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:50.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:48.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:10:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.71\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    408.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    408.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    408.    Elapsed: 0:02:57.\n",
            "  Batch   160  of    408.    Elapsed: 0:03:56.\n",
            "  Batch   200  of    408.    Elapsed: 0:04:55.\n",
            "  Batch   240  of    408.    Elapsed: 0:05:55.\n",
            "  Batch   280  of    408.    Elapsed: 0:06:55.\n",
            "  Batch   320  of    408.    Elapsed: 0:07:54.\n",
            "  Batch   360  of    408.    Elapsed: 0:08:54.\n",
            "  Batch   400  of    408.    Elapsed: 0:09:53.\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Training epcoh took: 0:10:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "  Validation took: 0:00:24\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "model_path = os.path.expanduser('~/med264/models_balanced/')\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    # Save the model\n",
        "    model.save_pretrained(model_path + str(epoch_i))\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save loss_values\n",
        "with open(model_path + 'loss_values.pickle', 'wb') as f:\n",
        "    pickle.dump(loss_values, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Let's take a look at our training loss over all batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "68xreA9JAmG5",
        "outputId": "7e4cc7cc-1327-47da-dae3-6095fce65551"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# Save the plot to file.\n",
        "plt.savefig(\"BERT_Fine_Tuning_balanced_loss.png\", dpi = 300)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save ipynb session\n",
        "import dill\n",
        "dill.dump_session('BERT_Fine_Tuning_Sentence_Classification_v2.db')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:LLM]",
      "language": "python",
      "name": "conda-env-LLM-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02c860af048a48039571df1ac10703a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1f85d855dc54d93b07370119c3fb96b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6ce09be5acce441494710b3c0cbc6169",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.78kB/s]"
          }
        },
        "03eb5cad0dd745feb519ae16bc13afd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b16898863445b485e301b75b1c918c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7fada7d50b514b38ad70fa3baf613c6f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1b80d80718874a95b805bca384538f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318e7d7d83c447a793316c7dda14a06d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf4b37cd06c34b6c995b02e30003ff38",
            "value": 466062
          }
        },
        "261c73d7337e4fd89c5512fd7cc801b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99320230aa154969ac7efcb4bd08e93a",
              "IPY_MODEL_1b80d80718874a95b805bca384538f9f",
              "IPY_MODEL_f1fb5bd99db34449aaa0775649c33ade"
            ],
            "layout": "IPY_MODEL_faa00d6df14a4229b40388dbf79b911f"
          }
        },
        "318e7d7d83c447a793316c7dda14a06d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3259bbb9cfbf4652944d6a63779c8536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03eb5cad0dd745feb519ae16bc13afd5",
              "IPY_MODEL_ab7f43db105a4c059816b83b8e3050ec",
              "IPY_MODEL_02c860af048a48039571df1ac10703a0"
            ],
            "layout": "IPY_MODEL_3276e0075f924285aaa17252d34217ba"
          }
        },
        "3276e0075f924285aaa17252d34217ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3387a402721d49db963b4e008e53fddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e41eb9e407642e2839dbea2c1d863f3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9f40f478367749d6ba370f73e016891b",
            "value": " 440M/440M [00:05&lt;00:00, 41.9MB/s]"
          }
        },
        "338a08d6c85e48e0b8ef1c0a083043fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55d9d13ce82b4950a54b33bb6733ea58",
              "IPY_MODEL_8ae18003614946a4b0cb39b81f5a6063",
              "IPY_MODEL_427bed3eb7e743f387a0dd6c23f031e9"
            ],
            "layout": "IPY_MODEL_632c81708e674a61b848d1fccab30084"
          }
        },
        "3496eb8998e64a38bf2ea922eec5f093": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e41eb9e407642e2839dbea2c1d863f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4171dca739984eb68291b7e8f337f372": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ba494ceeba44de99f69891d4fcfed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "427bed3eb7e743f387a0dd6c23f031e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9348b3637d2a4d2088281c8e34d98f3e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_41ba494ceeba44de99f69891d4fcfed7",
            "value": " 570/570 [00:00&lt;00:00, 38.0kB/s]"
          }
        },
        "4ae1954f09a04e0cb50a01a0154f64ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bb4b4d8abb34ffbafa2194402d755f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94d9470c01bd419dbf9f55fa69487ac9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4ae1954f09a04e0cb50a01a0154f64ec",
            "value": " 232k/232k [00:00&lt;00:00, 4.74MB/s]"
          }
        },
        "52b73c5ed8354070bbc22b6b74bde680": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d9d13ce82b4950a54b33bb6733ea58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec7c4858c9be4d359b77d390c432dbbb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_599f7a8f19874431bd445deda4c7b273",
            "value": "config.json: 100%"
          }
        },
        "571e6cb89b8d40cbaa812a53f895acdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "599f7a8f19874431bd445deda4c7b273": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "632c81708e674a61b848d1fccab30084": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a2a3be6805048539e68be9c9db64cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ce09be5acce441494710b3c0cbc6169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e89d82b8c9748138d79c28506876171": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fada7d50b514b38ad70fa3baf613c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82b16898863445b485e301b75b1c918c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae18003614946a4b0cb39b81f5a6063": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_571e6cb89b8d40cbaa812a53f895acdc",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a2a3be6805048539e68be9c9db64cc5",
            "value": 570
          }
        },
        "900a26c928b74d668a77dc97cc22995e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9348b3637d2a4d2088281c8e34d98f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942cfc1c25e54f088288dd44c9c708e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d9470c01bd419dbf9f55fa69487ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e88ebf979042b881d31e5bf447c956": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99320230aa154969ac7efcb4bd08e93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b73c5ed8354070bbc22b6b74bde680",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a747919a41ac43ae9baaf22c5654ca02",
            "value": "tokenizer.json: 100%"
          }
        },
        "9b263a3168674657b14223e58611f294": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e02c53a9b05047b0a3bfc9e47735ee43",
              "IPY_MODEL_b15d78f0355e4c55b9ce4480d42bd67c",
              "IPY_MODEL_4bb4b4d8abb34ffbafa2194402d755f8"
            ],
            "layout": "IPY_MODEL_eb60945d776d4b5a92870fa3371471f6"
          }
        },
        "9ed6e953f4d74267a34be03f6b19283a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f40f478367749d6ba370f73e016891b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a747919a41ac43ae9baaf22c5654ca02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7f43db105a4c059816b83b8e3050ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e9766eb48c4db09d5e9ec558802d25",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3496eb8998e64a38bf2ea922eec5f093",
            "value": 28
          }
        },
        "b15d78f0355e4c55b9ce4480d42bd67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4171dca739984eb68291b7e8f337f372",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ed6e953f4d74267a34be03f6b19283a",
            "value": 231508
          }
        },
        "b4e9766eb48c4db09d5e9ec558802d25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baa55ed847294bb3a7c954a53c238d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c32c896bfdc34392a7ad9e19705063ce",
              "IPY_MODEL_bf865e8dbc534bbd8369dd0f7922d889",
              "IPY_MODEL_3387a402721d49db963b4e008e53fddb"
            ],
            "layout": "IPY_MODEL_dd3ddfe03dcb41969725890fb0683062"
          }
        },
        "bf865e8dbc534bbd8369dd0f7922d889": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e51be70d014af6b935ad0adda4ee37",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dee07e9f2f6244f599a7df2e5334caea",
            "value": 440449768
          }
        },
        "c32c896bfdc34392a7ad9e19705063ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e89d82b8c9748138d79c28506876171",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_96e88ebf979042b881d31e5bf447c956",
            "value": "model.safetensors: 100%"
          }
        },
        "cf4b37cd06c34b6c995b02e30003ff38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd3ddfe03dcb41969725890fb0683062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee07e9f2f6244f599a7df2e5334caea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e02c53a9b05047b0a3bfc9e47735ee43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7286cb5f4e4afdb9b8403265e51f0c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fefd62e5e0064bb6a8ed1f750309b8a1",
            "value": "vocab.txt: 100%"
          }
        },
        "e1f85d855dc54d93b07370119c3fb96b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb60945d776d4b5a92870fa3371471f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec7c4858c9be4d359b77d390c432dbbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0e51be70d014af6b935ad0adda4ee37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1fb5bd99db34449aaa0775649c33ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_942cfc1c25e54f088288dd44c9c708e9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_900a26c928b74d668a77dc97cc22995e",
            "value": " 466k/466k [00:00&lt;00:00, 22.6MB/s]"
          }
        },
        "faa00d6df14a4229b40388dbf79b911f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fefd62e5e0064bb6a8ed1f750309b8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff7286cb5f4e4afdb9b8403265e51f0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
