{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/new-stg/home/banghua/anaconda3/envs/LLM/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-27 00:34:26.546335: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-27 00:34:26.578506: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-27 00:34:26.578532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-27 00:34:26.579376: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-27 00:34:26.584534: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 00:34:27.602620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 118,094\n",
      "\n",
      "Number of validation sentences: 14,601\n",
      "\n",
      "Number of testing sentences: 14,935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df_train = pd.read_csv(\"~/med264/Dataset1/day1_30mortality_train.csv\", index_col=0)\n",
    "df_val = pd.read_csv(\"~/med264/Dataset1/day1_30mortality_val.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"~/med264/Dataset1/day1_30mortality_test.csv\", index_col=0)\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df_train.shape[0]))\n",
    "print('Number of validation sentences: {:,}\\n'.format(df_val.shape[0]))\n",
    "print('Number of testing sentences: {:,}\\n'.format(df_test.shape[0]))\n",
    "\n",
    "# Get the lists of sentences and their labels.\n",
    "sentences_train = df_train.TEXT.values\n",
    "labels_train = df_train.Label.values\n",
    "sentences_val = df_val.TEXT.values\n",
    "labels_val = df_val.Label.values\n",
    "sentences_test = df_test.TEXT.values\n",
    "labels_test = df_test.Label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('medicalai/ClinicalBERT', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded input_ids_train.\n",
      "Loaded input_ids_valid.\n",
      "Loaded input_ids_test.\n",
      "Max train sentence length:  1200\n",
      "Max valid sentence length:  1123\n",
      "Max test sentence length:  890\n",
      "\n",
      "Padding/truncating all sentences to 512 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Correct the path by expanding the tilde to the user's home directory\n",
    "file_path_train = os.path.expanduser('~/med264/Dataset1/input_ids_train.pickle')\n",
    "file_path_valid = os.path.expanduser('~/med264/Dataset1/input_ids_valid.pickle')\n",
    "file_path_test = os.path.expanduser('~/med264/Dataset1/input_ids_test.pickle')\n",
    "\n",
    "\n",
    "input_ids_train, input_ids_valid, input_ids_test = [], [], []\n",
    "\n",
    "if os.path.exists(file_path_train):\n",
    "    with open(file_path_train, 'rb') as f:\n",
    "        input_ids_train = pickle.load(f)\n",
    "    print('Loaded input_ids_train.')\n",
    "else:\n",
    "    for sent in tqdm(sentences_train):\n",
    "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
    "        input_ids_train.append(encoded_sent)\n",
    "    with open(file_path_train, 'wb') as f:\n",
    "        pickle.dump(input_ids_train, f)\n",
    "    print('Saved input_ids_train.')\n",
    "\n",
    "\n",
    "if os.path.exists(file_path_valid):\n",
    "    with open(file_path_valid, 'rb') as f:\n",
    "        input_ids_valid = pickle.load(f)\n",
    "    print('Loaded input_ids_valid.')\n",
    "else:\n",
    "    for sent in tqdm(sentences_val):\n",
    "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
    "        input_ids_valid.append(encoded_sent)\n",
    "    with open(file_path_valid, 'wb') as f:\n",
    "        pickle.dump(input_ids_valid, f)\n",
    "    print('Saved input_ids_valid.')\n",
    "\n",
    "if os.path.exists(file_path_test):\n",
    "    with open(file_path_test, 'rb') as f:\n",
    "        input_ids_test = pickle.load(f)\n",
    "    print('Loaded input_ids_test.')\n",
    "else:\n",
    "    for sent in tqdm(sentences_test):\n",
    "        encoded_sent = tokenizer.encode(sent, add_special_tokens = True)\n",
    "        input_ids_test.append(encoded_sent)\n",
    "    with open(file_path_test, 'wb') as f:\n",
    "            pickle.dump(input_ids_test, f)\n",
    "    print('Saved input_ids_test.')\n",
    "    \n",
    "\n",
    "print('Max train sentence length: ', max([len(sen) for sen in input_ids_train]))\n",
    "print('Max valid sentence length: ', max([len(sen) for sen in input_ids_valid]))\n",
    "print('Max test sentence length: ', max([len(sen) for sen in input_ids_test]))\n",
    "\n",
    "# We'll borrow the `pad_sequences` utility function to do this.\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the maximum sequence length.\n",
    "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
    "# maximum training sentence length of 47...\n",
    "MAX_LEN = 512\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "input_ids_valid = pad_sequences(input_ids_valid, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                            value=0, truncating=\"post\", padding=\"post\")\n",
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                            value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')\n",
    "\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks_train, attention_masks_valid, attention_masks_test = [], [], []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids_train:\n",
    "\n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks_train.append(att_mask)\n",
    "\n",
    "for sent in input_ids_valid:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    attention_masks_valid.append(att_mask)\n",
    "\n",
    "for sent in input_ids_test:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    attention_masks_test.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, test_inputs, train_labels, validation_labels, test_labels =\\\n",
    "input_ids_train, input_ids_valid, input_ids_test, labels_train, labels_val, labels_test\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, test_masks = attention_masks_train, attention_masks_valid, attention_masks_test\n",
    "\n",
    "# Convert all inputs and labels into torch tensors, the required datatype\n",
    "# for our model.\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it\n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.expanduser('~/med264/models/')\n",
    "preds_path = os.path.expanduser('~/med264/preds/')\n",
    "\n",
    "# Check if preds_path exists, if not, create it\n",
    "if not os.path.exists(preds_path):\n",
    "    os.makedirs(preds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0:\n",
      "Loading model from /new-stg/home/banghua/med264/models/0/...\n",
      "Predicting labels for 118,094 train sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1846/1846 [15:05<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Accuracy: 0.89\n",
      "Predicting labels for 14,601 validation sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 229/229 [01:52<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Validation Accuracy: 0.90\n",
      "Predicting labels for 14,935 test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 234/234 [01:54<00:00,  2.04it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39m# Calculate the accuracy for this batch of test sentences.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m val_accuracy \u001b[39m=\u001b[39m accuracy_score(flat_true_labels_test, flat_predictions_test)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m  Test Accuracy: \u001b[39m\u001b[39m{0:.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(test_accuracy))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m acc_results[\u001b[39m'\u001b[39m\u001b[39mmodel_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i)] \u001b[39m=\u001b[39m {\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mtrain_accuracy\u001b[39m\u001b[39m'\u001b[39m: train_accuracy,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m: val_accuracy,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mtest_accuracy\u001b[39m\u001b[39m'\u001b[39m: test_accuracy\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m }\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m preds_results[\u001b[39m'\u001b[39m\u001b[39mmodel_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i)] \u001b[39m=\u001b[39m {\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mtrain_preds\u001b[39m\u001b[39m'\u001b[39m: flat_predictions_train,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mtrain_true_labels\u001b[39m\u001b[39m'\u001b[39m: flat_true_labels_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mtest_true_labels\u001b[39m\u001b[39m'\u001b[39m: flat_true_labels_test\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/xbh0403/Desktop/UCSD/23F_Q1/MED_264/MED_264/jupyer_notebooks/get_preds.ipynb#X11sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "acc_results = {}\n",
    "preds_results = {}\n",
    "\n",
    "for i in range(10):\n",
    "  print('Model ' + str(i) + ':')\n",
    "  model_path_i = os.path.expanduser('~/med264/models/' + str(i) + '/')\n",
    "  print('Loading model from ' + model_path_i + '...')\n",
    "  model = BertForSequenceClassification.from_pretrained(\n",
    "    model_path_i, num_labels = 2, output_attentions = False, output_hidden_states = False\n",
    "  )\n",
    "  model.cuda()\n",
    "  model.eval()\n",
    "\n",
    "  pred_path_i = os.path.expanduser('~/med264/preds/' + str(i) + '/')\n",
    "  # Check if pred_path_i exists, if not, create it\n",
    "  if not os.path.exists(pred_path_i):\n",
    "      os.makedirs(pred_path_i)\n",
    "  # Tracking variables\n",
    "  predictions_train, predictions_val, predictions_test = [], [], []\n",
    "  true_labels_train, true_labels_val, true_labels_test = [], [], []\n",
    "  # Predict\n",
    "  print('Predicting labels for {:,} train sentences...'.format(len(train_inputs)))\n",
    "  for batch in tqdm(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and\n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    # Store predictions and true labels\n",
    "    predictions_train.append(logits)\n",
    "    true_labels_train.append(label_ids)\n",
    "  flat_predictions_train = np.concatenate(predictions_train, axis=0)\n",
    "  flat_predictions_train = np.argmax(flat_predictions_train, axis=1).flatten()\n",
    "  flat_true_labels_train = np.concatenate(true_labels_train, axis=0)\n",
    "  # Calculate the accuracy for this batch of test sentences.\n",
    "  train_accuracy = accuracy_score(flat_true_labels_train, flat_predictions_train)\n",
    "  print('  Train Accuracy: {0:.2f}'.format(train_accuracy))\n",
    "\n",
    "  print('Predicting labels for {:,} validation sentences...'.format(len(validation_inputs)))\n",
    "  for batch in tqdm(validation_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and\n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    # Store predictions and true labels\n",
    "    predictions_val.append(logits)\n",
    "    true_labels_val.append(label_ids)\n",
    "  flat_predictions_val = np.concatenate(predictions_val, axis=0)\n",
    "  flat_predictions_val = np.argmax(flat_predictions_val, axis=1).flatten()\n",
    "  flat_true_labels_val = np.concatenate(true_labels_val, axis=0)\n",
    "  # Calculate the accuracy for this batch of test sentences.\n",
    "  val_accuracy = accuracy_score(flat_true_labels_val, flat_predictions_val)\n",
    "  print('  Validation Accuracy: {0:.2f}'.format(val_accuracy))\n",
    "\n",
    "  print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n",
    "  for batch in tqdm(test_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and\n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    # Store predictions and true labels\n",
    "    predictions_test.append(logits)\n",
    "    true_labels_test.append(label_ids)\n",
    "  flat_predictions_test = np.concatenate(predictions_test, axis=0)\n",
    "  flat_predictions_test = np.argmax(flat_predictions_test, axis=1).flatten()\n",
    "  flat_true_labels_test = np.concatenate(true_labels_test, axis=0)\n",
    "  # Calculate the accuracy for this batch of test sentences.\n",
    "  test_accuracy = accuracy_score(flat_true_labels_test, flat_predictions_test)\n",
    "  print('  Test Accuracy: {0:.2f}'.format(test_accuracy))\n",
    "\n",
    "  acc_results['model_' + str(i)] = {\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'val_accuracy': val_accuracy,\n",
    "    'test_accuracy': test_accuracy\n",
    "  }\n",
    "  \n",
    "  preds_results['model_' + str(i)] = {\n",
    "    'train_preds': flat_predictions_train,\n",
    "    'train_true_labels': flat_true_labels_train,\n",
    "    'val_preds': flat_predictions_val,\n",
    "    'val_true_labels': flat_true_labels_val,\n",
    "    'test_preds': flat_predictions_test,\n",
    "    'test_true_labels': flat_true_labels_test\n",
    "  }\n",
    "\n",
    "  print('Saving predictions...')\n",
    "  with open(pred_path_i + 'preds.pickle', 'wb') as f:\n",
    "    pickle.dump(preds_results['model_' + str(i)], f)\n",
    "  print('Saved predictions.')\n",
    "\n",
    "print('Saving overall results...')\n",
    "with open(preds_path + 'acc_results.pickle', 'wb') as f:\n",
    "  pickle.dump(acc_results, f)\n",
    "print('Saved overall results.')\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the accuracy for this batch of test sentences.\n",
    "accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Accuracy: {0:.2f}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LLM]",
   "language": "python",
   "name": "conda-env-LLM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
